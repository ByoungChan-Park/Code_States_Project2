{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning or RuntimeWarning)\n",
    "DATA_PATH = \"../../../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CB 모델의 성능을 검증한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리상에 여유를 위해 pickling 하는 함수\n",
    "def pickling(arg_object, arg_file_name):\n",
    "    with open(f'{arg_file_name}.pkl','wb') as pickle_file:\n",
    "        pickle.dump(arg_object, pickle_file)       \n",
    "    print(f\"{arg_file_name}.pkl로 pickling 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 pkl 파일을 불러오는 함수\n",
    "def test_pkl(name):\n",
    "    test = None\n",
    "    with open(f'{name}.pkl','rb') as pickle_file:\n",
    "        test = pickle.load(pickle_file)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson table 을 쉽게 만들기 위해 데이터를 가공후 data_for_pearson.parquet.gzip 으로 저장\n",
    "df = pd.read_csv(DATA_PATH + \"2019-Oct.csv\")\n",
    "df.dropna(inplace = True)\n",
    "df.drop(columns = [\"event_time\", \"category_id\", \"user_session\"], inplace = True)\n",
    "df = df[df[\"event_type\"] == \"view\"]\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df[\"category_code_0\"] = df[\"category_code\"].apply(lambda x : x.split(\".\")[0])\n",
    "df.to_parquet(DATA_PATH + \"data_for_pearson.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pearson_table(target_category):\n",
    "    '''\n",
    "    target_category 가 주어지면 해당 카테고리의 상품들로 pearson table을 만들어서 반환하는 함수\n",
    "    '''\n",
    "\n",
    "    # 데이터 불러오기 \n",
    "    df = pd.read_parquet(DATA_PATH + \"data_for_pearson.parquet.gzip\", columns = [\"product_id\", \"category_code\", \"brand\", \"price\", \"category_code_0\"])\n",
    "\n",
    "    # 해당 카테고리만 가져오기\n",
    "    df = df[df[\"category_code_0\"] == target_category]\n",
    "    df = df.reset_index(drop= True)\n",
    "\n",
    "    # 카테고리와 브랜드를 합친 category_code+brand 변수 생성\n",
    "    df[\"category_code+brand\"] = df[\"category_code\"] +  df[\"brand\"].apply(lambda x : \".\" + x)\n",
    "\n",
    "    # 제품별로 category_code+brand와 가격의 평균으로 보기\n",
    "    df = df.groupby(\"product_id\").agg({\"category_code+brand\" : \"unique\", \"price\" : \"mean\"})\n",
    "    df = df.reset_index()\n",
    "    df[\"category_code+brand\"] = df[\"category_code+brand\"].apply(lambda x : x[0])\n",
    "    \n",
    "    # 가격평균을 MinMaxScaler 를 이용하여 스케일링하기\n",
    "    # df_minmax 는 스케일링된 가격평균을 가지고 있는 DataFrame\n",
    "    scaler = MinMaxScaler()\n",
    "    df_minmax = scaler.fit_transform(df[[\"price\"]])\n",
    "    df_minmax = pd.DataFrame(df_minmax, columns=['mMprice'])\n",
    "    df_minmax.index = df['product_id'].values\n",
    "    del scaler\n",
    "\n",
    "    # CountVectorizer 적용\n",
    "    # sparse matrix 인 countvect 에서 직접 계산하면 더 효율적일 것으로 예상\n",
    "    vect = CountVectorizer()\n",
    "    docs = df['category_code+brand'].values\n",
    "    countvect = vect.fit_transform(docs)\n",
    "    countvect_df =pd.DataFrame(countvect.toarray(), columns = sorted(vect.vocabulary_))\n",
    "    countvect_df.index = df['product_id'].values\n",
    "    del vect, docs, countvect\n",
    "\n",
    "    # 제품을 index로 가지는 데이터(제품별 특징을 담고있다)\n",
    "    df = pd.concat([df_minmax, countvect_df], axis= 1)\n",
    "    del df_minmax, countvect_df\n",
    "\n",
    "    # 피어슨 유사도 계산\n",
    "    df = df.T.corr()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appliances_pearson_table.pkl로 pickling 완료\n",
      "computers_pearson_table.pkl로 pickling 완료\n",
      "electronics_pearson_table.pkl로 pickling 완료\n",
      "apparel_pearson_table.pkl로 pickling 완료\n",
      "furniture_pearson_table.pkl로 pickling 완료\n",
      "construction_pearson_table.pkl로 pickling 완료\n",
      "kids_pearson_table.pkl로 pickling 완료\n",
      "auto_pearson_table.pkl로 pickling 완료\n",
      "sport_pearson_table.pkl로 pickling 완료\n",
      "accessories_pearson_table.pkl로 pickling 완료\n",
      "medicine_pearson_table.pkl로 pickling 완료\n",
      "stationery_pearson_table.pkl로 pickling 완료\n",
      "country_yard_pearson_table.pkl로 pickling 완료\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_PATH + \"data_for_pearson.parquet.gzip\", columns = [\"category_code_0\"])\n",
    "category_code_list = list(df[\"category_code_0\"].unique())\n",
    "del df\n",
    "\n",
    "# 각 카테고리별로 pearson table을 생성하고 저장한다.\n",
    "for category_code in category_code_list:\n",
    "    df = make_pearson_table(target_category = category_code)\n",
    "    pickling(df, f\"{category_code}_pearson_table\")\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 카테고리별로 pearson 유사도를 계산해서 해당 유저가 가장 많이 본 상품과 비슷한 상품 10개를 추천한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id_to_category_code_0.pkl로 pickling 완료\n"
     ]
    }
   ],
   "source": [
    "# product_id 입력받으면 해당 제품의 1차 카테고리를 반환하는 dict 생성\n",
    "df = pd.read_parquet(DATA_PATH + \"data_for_pearson.parquet.gzip\", columns = [\"product_id\", \"category_code_0\"])\n",
    "df = df.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=True)\n",
    "product_id_to_category_code_0 = {product_id : category_code_0 for product_id, category_code_0 in list(zip(df[\"product_id\"], df[\"category_code_0\"]))}\n",
    "pickling(product_id_to_category_code_0, \"product_id_to_category_code_0\")\n",
    "del product_id_to_category_code_0, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조회한 상품의 종류가 2개이상 10개 이하인 유저만 불러오기\n",
    "df = pd.read_parquet(DATA_PATH + \"data_for_pearson.parquet.gzip\", columns = [\"product_id\", \"user_id\"])\n",
    "df = df.groupby(\"user_id\").nunique()\n",
    "df = df[(df[\"product_id\"] >= 2) & (df[\"product_id\"] <= 10)]\n",
    "lower_user_list = df.index\n",
    "df = pd.read_parquet(DATA_PATH + \"data_for_pearson.parquet.gzip\", columns = [\"user_id\", \"product_id\", \"event_type\"])\n",
    "df = df[df[\"user_id\"].isin(lower_user_list)]  \n",
    "df = df.reset_index(drop =True)\n",
    "df = df.groupby([\"user_id\", \"product_id\"]).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1177302x51628 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5058355 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 csr_matrix로 만드는 과정입니다.\n",
    "user_unique = df['user_id'].unique()\n",
    "product_unique = df['product_id'].unique()\n",
    "cb_user_to_index = {user:index for index, user in enumerate(user_unique)}\n",
    "cb_index_to_user = {index:user for index, user in enumerate(user_unique)}\n",
    "cb_product_to_index = {product:index for index, product in enumerate(product_unique)}\n",
    "cb_index_to_product = {index:product for index, product in enumerate(product_unique)}\n",
    "df['user_id'] = df['user_id'].map(cb_user_to_index.get)\n",
    "df['product_id'] = df['product_id'].map(cb_product_to_index.get)\n",
    "num_user = df['user_id'].nunique()\n",
    "num_product = df['product_id'].nunique()\n",
    "lower_user_item_matrix = csr_matrix((df.event_type, (df.user_id, df.product_id)), shape= (num_user, num_product))\n",
    "\n",
    "del df, user_unique, product_unique\n",
    "\n",
    "lower_user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 평가를 위해 한 유저당 임의의 상품 하나의 view기록을 0으로 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc17c5dab293498b955e087a2439c8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1177302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 유저마다 랜덤하게 하나씩 0으로 가리는 작업입니다.\n",
    "samples = []\n",
    "\n",
    "for user_idx in tqdm(range(num_user)) :\n",
    "    samples.append((user_idx, random.sample(lower_user_item_matrix[user_idx].nonzero()[1].tolist(), 1)[0]))\n",
    "    \n",
    "training_set = lower_user_item_matrix.copy()\n",
    "test_set = lower_user_item_matrix.copy()\n",
    "\n",
    "user_inds = [index[0] for index in samples]\n",
    "item_inds = [index[1] for index in samples]\n",
    "\n",
    "training_set[user_inds, item_inds] = 0\n",
    "training_set.eliminate_zeros()\n",
    "\n",
    "del lower_user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저별로 가장 view 수가 큰 product_id를 가지는 list\n",
    "input_data = list(np.array(np.argmax(training_set, axis=1)).reshape(-1))\n",
    "input_data = list(map(cb_index_to_product.get, input_data))\n",
    "\n",
    "# 가려진 product_id를 가지는 list\n",
    "label = list(map(cb_index_to_product.get, item_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c834adc6c83247cbad33b020ad04abfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 표본으로 Hit rate 검증 하기\n",
    "df = pd.read_parquet(DATA_PATH + \"data_for_pearson.parquet.gzip\", columns = [\"product_id\", \"event_type\"])\n",
    "df = df.groupby(\"product_id\").count()\n",
    "popular_product_id_list = list(df.sort_values(\"event_type\", ascending=False).index[:10])\n",
    "del df\n",
    "product_id_to_category_code_0 = test_pkl(\"product_id_to_category_code_0\")\n",
    "answer_store_by_model = []\n",
    "answer_store_by_pop = []\n",
    "sample_size = 10000\n",
    "for user_index in tqdm(np.random.randint(training_set.shape[1], size=sample_size)):\n",
    "    input_product_id = input_data[user_index]\n",
    "    input_category_code = product_id_to_category_code_0[input_product_id]\n",
    "    pearson_table = test_pkl(f\"{input_category_code}_pearson_table\")\n",
    "    viewed_product_index_list = list(np.where(training_set[user_index].toarray()[0] != 0)[0])\n",
    "    viewed_product_id_list = list(map(cb_index_to_product.get, viewed_product_index_list ))\n",
    "    pearson_table = pearson_table[~pearson_table.index.isin(viewed_product_id_list)]\n",
    "    answer_by_model = label[user_index] in list(pearson_table[input_product_id].sort_values(ascending=False).index[:10])\n",
    "    answer_store_by_model.append(answer_by_model)\n",
    "    answer_by_pop = label[user_index] in popular_product_id_list\n",
    "    answer_store_by_pop.append(answer_by_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CB 모델의 Hit rate = 0.1314\n",
      "Baseline 모델의 Hit rate = 0.1157\n",
      "검정통계량 값 = 3.373647532876431\n",
      "유의확률 = 0.0003708964188694486\n"
     ]
    }
   ],
   "source": [
    "# 귀무가설 : cb 모델을 사용하는것의 정확도와 가장조회수가 높은 것을 추천하는것의 Hit rate보다 작거나 같다.\n",
    "# 대립가설 : cb 모델을 사용하는것의 정확도가 가장조회수가 높은 것을 추천하는것의 Hit rate보다 크다.\n",
    "\n",
    "model = sum(answer_store_by_model)/len(answer_store_by_model)\n",
    "pop = sum(answer_store_by_pop)/len(answer_store_by_pop)\n",
    "print(f\"CB 모델의 Hit rate = {model}\")\n",
    "print(f\"Baseline 모델의 Hit rate = {pop}\")\n",
    "\n",
    "pool = (sample_size * (model + pop)) / (sample_size * 2)\n",
    "Z = (model - pop) / np.sqrt(pool * (1 - pool) * (1/sample_size + 1/sample_size))\n",
    "print(f\"검정통계량 값 = {Z}\")\n",
    "print(f\"유의확률 = {1 - norm.cdf(Z)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유의수준 0.01 하에서 귀무가설을 기각한다.  \n",
    "cb 모델을 사용하는것의 Hit rate가 가장조회수가 높은 것을 추천하는것의 Hit rate보다 크다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
